# This is a basic workflow to help you get started with Actions

name: CI

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the "main" branch
  push:
    branches: [ "testload" ]
    paths:
      - .github/workflows/blank.yml
      

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest
    env:
      SQL_SERVER: "kafkaeunnprodsqlserver0001.database.windows.net"
      SQL_DATABASE: "kafkaeunnprodsqldb0001"
      SQL_USER: "kafkaadmin01"
      SQL_PASSWORD: ${{ secrets.DB_PASSWORD }}

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v3

      - name: Install http (HTTPie)
        run: |
          sudo apt-get update
          sudo apt-get install -y httpie
          http --version
          start_date=$(date -d "$(date '+%Y-%m-01')" '+%Y-%m-%d')

          # Current month's end date
          end_date=$(date -d "$(date -d "$(date '+%Y-%m-01') +1 month" '+%Y-%m-01') -1 day" '+%Y-%m-%d')
          
          # Displaying the results
          echo "Start date: $start_date"
          echo "End date: $end_date"

          yesterday=$(date -d 'yesterday' '+%Y-%m-%d')
          
          # Today's date
          today=$(date '+%Y-%m-%d')
          
          # Displaying the results
          echo "Yesterday's date: $yesterday"
          echo "Today's date: $today"
          pwd
          ls -lR


      - name: Install Confluent Cloud CLI
        run: |
          sudo curl -sL --http1.1 https://cnfl.io/cli | sh -s -- latest
          pwd
          ls -latr ./bin
          echo $PATH
          export PATH=$PATH:`pwd`/bin
          echo $PATH

      - name: Verify Installations
        run: |
          echo $PATH
          export PATH=$PATH:`pwd`/bin
          http --version
          confluent version
          yesterday=$(date -d 'yesterday' '+%Y-%m-%d')
          today=$(date '+%Y-%m-%d')
          
          # Displaying the results
          for clustername in  "lkc-38p82m"  "lkc-nzvwz" "lkc-xw9vx" 
          do
          echo $clustername
          echo "Yesterday's date: $yesterday"
          echo "Today's date: $today"
          cp received_bytes_query.json $clustername.received_bytes_query.json
          cp retained_bytes_query.json $clustername.retained_bytes_query.json
          cp sent_bytes_query.json $clustername.sent_bytes_query.json
          
          sed -i "s/yesterday/$yesterday/g" $clustername.*json
          sed -i "s/today/$today/g" $clustername.*json
          sed -i "s/clustername/$clustername/g" $clustername.*json
          
          echo " ======= $clustername.received_bytes_query.json ========"
          cat $clustername.received_bytes_query.json
          http 'https://api.telemetry.confluent.cloud/v2/metrics/cloud/query' --auth ${{ secrets.CC_KEY_FINOPS }} < $clustername.received_bytes_query.json | jq -r  '.data[] |  [.timestamp , ."metric.topic" ,  .value] | @csv' | sed 's/T00:00:00Z//g' | sed 's/"//g' | sort | awk -F',' '$NF > 0.0' > $clustername.received_bytes_query.csv
          echo " ======= $clustername.retained_bytes_query.json ========"
          cat $clustername.retained_bytes_query.json
          http 'https://api.telemetry.confluent.cloud/v2/metrics/cloud/query' --auth ${{ secrets.CC_KEY_FINOPS }} < $clustername.retained_bytes_query.json | jq -r  '.data[] |  [.timestamp , ."metric.topic" ,  .value] | @csv' | sed 's/T00:00:00Z//g' | sed 's/"//g' | sort | awk -F',' '$NF > 0.0' > $clustername.retained_bytes_query.csv
          echo " ======= $clustername.sent_bytes_query.json ========"
          cat $clustername.sent_bytes_query.json
          http 'https://api.telemetry.confluent.cloud/v2/metrics/cloud/query' --auth ${{ secrets.CC_KEY_FINOPS }} < $clustername.sent_bytes_query.json | jq -r  '.data[] |  [.timestamp , ."metric.topic" ,  .value] | @csv'  | sed 's/T00:00:00Z//g' | sed 's/"//g' | sort | awk -F',' '$NF > 0.0' > $clustername.sent_bytes_query.csv
          
          done
          wc -l *.csv
          PRIVATEDEV=` http 'https://api.telemetry.confluent.cloud/v2/metrics/cloud/query' --auth ${{ secrets.CC_KEY_FINOPS }} < lkc-38p82m.retained_bytes_query.json | jq -r  '.data[] |  [.timestamp , ."metric.topic" ,  .value] | @csv' | wc -l`
          PROD=`http 'https://api.telemetry.confluent.cloud/v2/metrics/cloud/query' --auth ${{ secrets.CC_KEY_FINOPS }} < lkc-xw9vx.retained_bytes_query.json | jq -r  '.data[] |  [.timestamp , ."metric.topic" ,  .value] | @csv'  | wc -l`
          PUBLICPROD=`http 'https://api.telemetry.confluent.cloud/v2/metrics/cloud/query' --auth ${{ secrets.CC_KEY_FINOPS }} < lkc-nzvwz.retained_bytes_query.json | jq -r  '.data[] |  [.timestamp , ."metric.topic" ,  .value] | @csv'  | wc -l`
          
          
          #echo "$yesterday,lkc-kxo2p,sandpit-cluster-0,$sandpitcluster"
          #echo "$yesterday,lkc-ojx6o,cluster_perf_01,$clusterperf"
          echo "$yesterday,lkc-38p82m,PRIVATE-DEV/PRE-PROD,$PRIVATEDEV" > topiccount.csv
          echo "$yesterday,lkc-xw9vx,DIGITAL-NEU-MULTIZONE-CLUSTER-02,$PROD" >> topiccount.csv
          echo "$yesterday,lkc-nzvwz,PUBLIC-PROD,$PUBLICPROD" >> topiccount.csv
          cat topiccount.csv


          # http 'https://api.telemetry.confluent.cloud/v2/metrics/cloud/query' --auth ${{ secrets.CC_KEY_FINOPS }} < received_bytes_query.json | jq -r  '.data[] |  [.timestamp , .value] | @csv'
          # http 'https://api.telemetry.confluent.cloud/v2/metrics/cloud/query' --auth ${{ secrets.CC_KEY_FINOPS }} < received_bytes_query.json | jq -r  '.data[] |  [.timestamp , ."metric.topic" ,  .value] | @csv'
  
      - name: Log in to Confluent Cloud
        run: |
          export PATH=$PATH:`pwd`/bin
          start_date=$(date -d "$(date '+%Y-%m-01')" '+%Y-%m-%d')
          end_date=$(date -d "$(date -d "$(date '+%Y-%m-01') +1 month" '+%Y-%m-01') -1 day" '+%Y-%m-%d')
          
          # Displaying the results
          echo "Start date: $start_date"
          echo "End date: $end_date"
          confluent login --save
          confluent billing cost list --start-date  $start_date --end-date  $end_date | grep -v "^-" |  sed 's/|/,/g' | tr -s ' ' | tr -d ' ' | sed 's/\$//g' | tail -n +2 > daily_billing.csv

        env:
          CONFLUENT_CLOUD_EMAIL: ${{ secrets.CONFLUENT_CLOUD_EMAIL }}
          CONFLUENT_CLOUD_PASSWORD: ${{ secrets.CONFLUENT_CLOUD_PASSWORD }}        
      - name: Install dependencies
        run: |
          export PATH=$PATH:`pwd`/bin
          #python -m pip install --upgrade pip
          #pip install mssql-cli
          ls -l /opt
          ls -lR /opt/mssql-tools/bin
          /opt/mssql-tools/bin/sqlcmd -S $SQL_SERVER -U $SQL_USER -P $SQL_PASSWORD  -q "SELECT @@VERSION"
          sh test/exec_sqlcmd_may24.sh
          #/opt/mssql-tools/bin/sqlcmd -S $SQL_SERVER -U $SQL_USER -P $SQL_PASSWORD  -q "delete from daily_base" -d kafkaeunnprodsqldb0001
          #bcp kafkaeunnprodsqldb0001.dbo.daily_base in daily_billing.csv  -S  $SQL_SERVER -U $SQL_USER -P $SQL_PASSWORD  -q -c -t ","
          #mssql-cli -S $SQL_SERVER -d $SQL_DATABASE -U $SQL_USER -P $SQL_PASSWORD 

      - name: Connect to Azure SQL Database
        run: |
          #mssql-cli -S $SQL_SERVER -d $SQL_DATABASE -U $SQL_USER -P $SQL_PASSWORD  
          #/opt/mssql-tools/bin/sqlcmd -S $SQL_SERVER -U $SQL_USER -P $SQL_PASSWORD  -q "SELECT @@VERSION"
          #/opt/mssql-tools/bin/sqlcmd -S $SQL_SERVER -U $SQL_USER -P $SQL_PASSWORD  -q "delete from daily_base"
          #/opt/mssql-tools/bin/sqlcmd -S $SQL_SERVER -U $SQL_USER -P $SQL_PASSWORD  -q "select * from kafkaeunnprodsqldb0001.dbo.daily_base"
          #cat daily_billing.csv
          ##bcp kafkaeunnprodsqldb0001.dbo.daily_trans_topics_data in received_bytes_query.csv  -S $SQL_SERVER -U $SQL_USER -P $SQL_PASSWORD -q -c -t ","
          #bcp kafkaeunnprodsqldb0001.dbo.daily_base in daily_billing.csv  -S  $SQL_SERVER -U $SQL_USER -P $SQL_PASSWORD  -q -c -t ","

